import os
import numpy as np
import tensorflow as tf
from keras.models import Model,load_model
from keras.layers import LSTM, Dense, Dropout, Input, Masking, Flatten, Attention
from keras.optimizers import Adam
from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix,roc_auc_score
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

# å®šä¹‰å¸¦æ³¨æ„åŠ›çš„ LSTM æ¨¡å‹
def attention(input_shape, epochs=10, batch_size=64):
    inputs = Input(shape=input_shape)
    masked_input = Masking(mask_value=0.0)(inputs)
    lstm_out = LSTM(128, return_sequences=True)(masked_input)
    lstm_out2 = LSTM(64, return_sequences=True)(lstm_out)
    
    # æ·»åŠ æ³¨æ„åŠ›å±‚
    attention_out = Attention()([lstm_out2, lstm_out2])
    
    # Flattenå±‚
    flattened_out = Flatten()(attention_out)
    
    # å¯†é›†å±‚
    dense_out = Dense(25, activation='sigmoid')(flattened_out)
    output = Dense(1, activation='sigmoid')(dense_out)

    model = Model(inputs=inputs, outputs=output)
    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

    return model

# è¯„ä¼°æ¨¡å‹æ€§èƒ½çš„å‡½æ•°
# ===== è¯„ä¼°å‡½æ•° =====
def evaluate_model(model_path, test_X, test_Y):
    try:
        model = load_model(model_path)
    except:
        print(f"âŒ Failed to load model: {model_path}")
        return None

    y_pred = model.predict(test_X, verbose=0)[:, 0]
    y_class = (y_pred > 0.5).astype(int)
    acc = accuracy_score(test_Y, y_class)
    prec = precision_score(test_Y, y_class)
    rec = recall_score(test_Y, y_class)
    f1 = f1_score(test_Y, y_class)
    auc = roc_auc_score(test_Y, y_pred)
    tn, fp, fn, tp = confusion_matrix(test_Y, y_class).ravel()
    return dict(acc=acc, precision=prec, recall=rec, f1=f1, auc=auc, tn=tn, fp=fp, fn=fn, tp=tp)


# ===== ä¸»æµç¨‹ =====
if __name__ == "__main__":
    results = []  # åˆå¹¶æ‰€æœ‰æ–¹æ³•çš„ç»“æœ

    master_data_sizes = [12, 18]
    split_ratios = [1, 2, 5, 10, 25]
    sampling_methods = ['original', 'random', 'tSMOTE', 'timeGAN']

    for method in sampling_methods:
        for master_data_size in master_data_sizes:
            for ratio in split_ratios:
                testX_path = f"data/test_{method}_2019_master{master_data_size}_ratio1to{ratio}/testX.npy"
                testY_path = f"data/test_{method}_2019_master{master_data_size}_ratio1to{ratio}/testY.npy"
                if not os.path.exists(testX_path):
                    continue
                test_X = np.load(testX_path)
                test_Y = np.load(testY_path)

                for run in range(1, 3):
                    model_path = f"å®éªŒä¸‰models/çœŸKAN/{method}/LSTM_Attention_best_model_master_data_size_{master_data_size}_ratio1to{ratio}_run_{run}.h5"
                    print(f"ğŸ” Evaluating: {method} | size={master_data_size} | ratio=1:{ratio} | run={run}")
                    result = evaluate_model(model_path, test_X, test_Y)
                    if result:
                        result.update(dict(
                            method=method,
                            master_data_size=master_data_size,
                            split_ratio=ratio,
                            run=run
                        ))
                        results.append(result)

    # ğŸ“ æ‰€æœ‰æ–¹æ³•çš„ç»“æœç»Ÿä¸€ä¿å­˜
    df = pd.DataFrame(results)
    output_csv = "E3_LSTM_Attention_all_results.csv"
    df.to_csv(output_csv, index=False)
    print(f"âœ… All results saved to {output_csv}")
